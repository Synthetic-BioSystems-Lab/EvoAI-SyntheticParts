{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import getpass\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing SynBioHub to pull iGEM parts registry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.post(\n",
    "#     'https://synbiohub.org/login',\n",
    "#     headers={\n",
    "#         'Accept': 'text/plain'\n",
    "#     },\n",
    "#     data={\n",
    "#         'email': input('SynBioHub email: '),\n",
    "#         'password' : getpass.getpass('Password: '),\n",
    "#         },\n",
    "# )\n",
    "\n",
    "# print(response.status_code)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unable to access SynBioHub right\n",
    "\n",
    "Need to build method to access larger database of genetic parts sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(\n",
    "#     'https://synbiohub.org/rootCollections',\n",
    "#     headers={\n",
    "#         'Accept': 'text/plain',\n",
    "#         'X-authorization': response.content\n",
    "#         },\n",
    "# )\n",
    "\n",
    "# print(response.status_code)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(\n",
    "#     'https://synbiohub.org/public/igem/igem_collection/1/sbol',\n",
    "#     headers={\n",
    "#         'Accept': 'text/plain',\n",
    "#         'X-authorization': response.content\n",
    "#         },\n",
    "# )\n",
    "\n",
    "# print(response.status_code)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Search for DNA sequences using regular expression\n",
    "# dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', response.content.decode('utf-8'), re.DOTALL)\n",
    "\n",
    "# # Create a pandas dataframe\n",
    "# df = pd.DataFrame(dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "\n",
    "# # Print the dataframe\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using downloaded promoter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "23\n",
      "611\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "promoters_2019 = open('./data_collection/SBOL_Files/iGEM_2019_Promoters_collection.xml').read()\n",
    "\n",
    "rbs_2019 = open('./data_collection/SBOL_files/iGEM_2019_RBSs_collection.xml').read()\n",
    "\n",
    "cds_2019 = open('./data_collection/SBOL_files/iGEM_2019_CDS_collection.xml').read()\n",
    "\n",
    "t_2019 = open('data_collection/SBOL_files/iGEM_2019_Terminators_collection.xml').read()\n",
    "\n",
    "\n",
    "# Search for DNA sequences using regular expression\n",
    "# Promoters\n",
    "p19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', promoters_2019, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "p19_df = pd.DataFrame(p19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(p19_df))\n",
    "# Print the dataframe\n",
    "#print(p19_df)\n",
    "\n",
    "# RBS\n",
    "rbs19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', rbs_2019, re.DOTALL)\n",
    "rbs19_df = pd.DataFrame(rbs19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "#print(rbs19_df)\n",
    "print(len(rbs19_df))\n",
    "\n",
    "# CDS\n",
    "cds19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', cds_2019, re.DOTALL)\n",
    "cds19_df = pd.DataFrame(cds19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(cds19_df))\n",
    "\n",
    "# Terminators\n",
    "t19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', t_2019, re.DOTALL)\n",
    "t19_df = pd.DataFrame(t19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(t19_df))\n",
    "\n",
    "# why is the first name of the df the name of the collection? \n",
    "# for now, will remove first row so that we have realistic names\n",
    "p19_df = p19_df.drop(p19_df.index[0])\n",
    "\n",
    "# add in promoter label for these seqs\n",
    "p19_df['Element'] = \"Promoter\"\n",
    "\n",
    "rbs19_df = rbs19_df.drop(rbs19_df.index[0])\n",
    "rbs19_df['Element'] = \"RBS\"\n",
    "\n",
    "cds19_df = cds19_df.drop(cds19_df.index[0])\n",
    "cds19_df['Element'] = \"CDS\"\n",
    "\n",
    "t19_df = t19_df.drop(t19_df.index[0])\n",
    "t19_df['Element'] = \"Terminator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>DNA Sequence</th>\n",
       "      <th>Element</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BBa_J05209</td>\n",
       "      <td>taacaccgtgcgtgttgactattttacctctggcggtgataatggttgc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BBa_I732406</td>\n",
       "      <td>aattgtgagcgctcacaatttttacactttatgcttccggctcgta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BBa_K1773016</td>\n",
       "      <td>acctgtaggatcgtacaggtttacgcaagaaaatggtttgttatag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BBa_K2117000</td>\n",
       "      <td>agagaccgggttggcggcgtatttgtgtcccaaaaaacagccccaa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BBa_K1444002</td>\n",
       "      <td>ggagttctgagaattggtatgccttataagtccaattaacagttga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>3171</td>\n",
       "      <td>BBa_R2108</td>\n",
       "      <td>tttatcaaaaagagtgttgacatttttaagtcccacgcgtgggatt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>3172</td>\n",
       "      <td>BBa_K1444025</td>\n",
       "      <td>ggagttctgagaattggtatgccttataagtccaattaacagttga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>3173</td>\n",
       "      <td>BBa_K879037</td>\n",
       "      <td>ttgatattgtgagcggataacaagatatc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>3174</td>\n",
       "      <td>BBa_I15008</td>\n",
       "      <td>atgagtgtcaacttagcttcccagttgcgggaagggacgaaaaaat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>3175</td>\n",
       "      <td>BBa_K1387002</td>\n",
       "      <td>atgtccagattagataaaagtaaagtgattaacagcgcattagagc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3175 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index          Name                                       DNA Sequence  \\\n",
       "0         1    BBa_J05209  taacaccgtgcgtgttgactattttacctctggcggtgataatggttgc   \n",
       "1         2   BBa_I732406  aattgtgagcgctcacaatttttacactttatgcttccggctcgta...   \n",
       "2         3  BBa_K1773016  acctgtaggatcgtacaggtttacgcaagaaaatggtttgttatag...   \n",
       "3         4  BBa_K2117000  agagaccgggttggcggcgtatttgtgtcccaaaaaacagccccaa...   \n",
       "4         5  BBa_K1444002  ggagttctgagaattggtatgccttataagtccaattaacagttga...   \n",
       "...     ...           ...                                                ...   \n",
       "3170   3171     BBa_R2108  tttatcaaaaagagtgttgacatttttaagtcccacgcgtgggatt...   \n",
       "3171   3172  BBa_K1444025  ggagttctgagaattggtatgccttataagtccaattaacagttga...   \n",
       "3172   3173   BBa_K879037                      ttgatattgtgagcggataacaagatatc   \n",
       "3173   3174    BBa_I15008  atgagtgtcaacttagcttcccagttgcgggaagggacgaaaaaat...   \n",
       "3174   3175  BBa_K1387002  atgtccagattagataaaagtaaagtgattaacagcgcattagagc...   \n",
       "\n",
       "      Element  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "3170        1  \n",
       "3171        1  \n",
       "3172        1  \n",
       "3173        1  \n",
       "3174        1  \n",
       "\n",
       "[3175 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "promoters_toValidate = open('./data_collection/SBOL_files/iGEM_Promoters_collection.xml').read()\n",
    "\n",
    "allPromoters_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', promoters_toValidate, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "allPromoters_df = pd.DataFrame(allPromoters_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "allPromoters_df = allPromoters_df.drop(allPromoters_df.index[0]).reset_index()\n",
    "allPromoters_df['Element'] = 1\n",
    "allPromoters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DNA Sequence</th>\n",
       "      <th>Element</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBa_K823010</td>\n",
       "      <td>ctgatggctagctcagtcctagggattatgctagc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBa_R0010</td>\n",
       "      <td>caatacgcaaaccgcctctccccgcgcgttggccgattcattaatg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBa_K823005</td>\n",
       "      <td>tttacagctagctcagtcctaggtattatgctagc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBa_K823012</td>\n",
       "      <td>tttatagctagctcagtcctaggtacaatgctagc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBa_K733013</td>\n",
       "      <td>aattttgtcaaaataattttattgacaacgtcttattaacgttgat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>BBa_K1689018</td>\n",
       "      <td>atgggatccgcggaggatatggctgccgacgaaatgcatcatcatc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>BBa_K801070</td>\n",
       "      <td>tacacaatgtctttacaagaagtcttgagaatgaacggtggtgaag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>BBa_B0013</td>\n",
       "      <td>aaaaaatcaaactggctcaccttcgggtgggcctttttgcgtttata</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>BBa_B0023</td>\n",
       "      <td>tataaacgcaaaaaggcccacccgaaggtgagccagtttgatttttt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>BBa_B0012</td>\n",
       "      <td>tcacactggctcaccttcgggtgggcctttctgcgtttata</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name                                       DNA Sequence Element\n",
       "0     BBa_K823010                ctgatggctagctcagtcctagggattatgctagc       1\n",
       "1       BBa_R0010  caatacgcaaaccgcctctccccgcgcgttggccgattcattaatg...       1\n",
       "2     BBa_K823005                tttacagctagctcagtcctaggtattatgctagc       1\n",
       "3     BBa_K823012                tttatagctagctcagtcctaggtacaatgctagc       1\n",
       "4     BBa_K733013  aattttgtcaaaataattttattgacaacgtcttattaacgttgat...       1\n",
       "..            ...                                                ...     ...\n",
       "778  BBa_K1689018  atgggatccgcggaggatatggctgccgacgaaatgcatcatcatc...       0\n",
       "779   BBa_K801070  tacacaatgtctttacaagaagtcttgagaatgaacggtggtgaag...       0\n",
       "780     BBa_B0013    aaaaaatcaaactggctcaccttcgggtgggcctttttgcgtttata       0\n",
       "781     BBa_B0023    tataaacgcaaaaaggcccacccgaaggtgagccagtttgatttttt       0\n",
       "782     BBa_B0012          tcacactggctcaccttcgggtgggcctttctgcgtttata       0\n",
       "\n",
       "[783 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "pro_rbs_cds_ter_df = pd.concat([p19_df, rbs19_df, cds19_df, t19_df], ignore_index=True)\n",
    "for i in range(len(pro_rbs_cds_ter_df)):\n",
    "    if pro_rbs_cds_ter_df.loc[i]['Element'] == 'Promoter':\n",
    "        pro_rbs_cds_ter_df.at[i,'Element'] = 1\n",
    "    else: \n",
    "        pro_rbs_cds_ter_df.at[i,'Element'] = 0\n",
    "pro_rbs_cds_ter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EDIT** Transform the string data into vectors for use in PyTorch\n",
    "We generate a dictionary with (keys, values) as (sequence, array). Where the arrays are numerical translations of the sequence based on the following: \n",
    "\n",
    "'a': [1.0, 0.0, 0.0, 0.0]  \n",
    "'c': [0.0, 1.0, 0.0, 0.0]  \n",
    "'g': [0.0, 0.0, 1.0, 0.0]  \n",
    "'t': [0.0, 0.0, 0.0, 1.0]  \n",
    "\n",
    "We also generate a correponding list of element labels to use for training with promoters as 1 and other parts as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequence(seq, max_len):\n",
    "    vec_dict = {'a': [1.0, 0.0, 0.0, 0.0],\n",
    "                'c': [0.0, 1.0, 0.0, 0.0],\n",
    "                'g': [0.0, 0.0, 1.0, 0.0],\n",
    "                't': [0.0, 0.0, 0.0, 1.0]}\n",
    "    vector = np.array([vec_dict[n] for n in seq])\n",
    "\n",
    "    vector = np.append(vector, np.zeros(((max_len-len(vector)), 4)))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros((2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PyTorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7891\n"
     ]
    }
   ],
   "source": [
    "max_len = allPromoters_df['DNA Sequence'].map(len).max()\n",
    "print(max_len)\n",
    "new_vec = torch.tensor(vectorize_sequence(allPromoters_df.loc[1]['DNA Sequence'], max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the dataset class\n",
    "class promoterDataset(Dataset):\n",
    "    def __init__(self, df, seq_col='DNA Sequence', element_col='Element'):\n",
    "\n",
    "        self.seqs = df[seq_col].to_list()\n",
    "        self.seq_len = len(self.seqs[0])\n",
    "        ### X values  ****we introduce padding to these tensors in order to create the stack. This may introduce bias.\n",
    "        max_len = df[seq_col].map(len).max()\n",
    "        self.veq_seqs = torch.stack([torch.tensor(vectorize_sequence(x, max_len)) for x in self.seqs])\n",
    "\n",
    "        ### Y values\n",
    "        self.labels = torch.tensor(list(df[element_col].values)).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        seq = self.vec_seqs[index]\n",
    "        label = self.label[index]\n",
    "        return seq, label\n",
    "    \n",
    "#initialize the data into correct form\n",
    "training_data = promoterDataset(allPromoters_df)\n",
    "test_data = promoterDataset(pro_rbs_cds_ter_df)\n",
    "\n",
    "train_dataloader = DataLoader(training_data)\n",
    "test_dataloader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Optimizing GPU > MPS > CPU\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic CNN model based on https://github.com/erinhwilson/dna-pytorch-tutorial/blob/c3abe167889a0018dba587ae7c3685920dbb928b/basic_DNA_tutorial.ipynb\n",
    "\n",
    "class Promoter_CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_len,\n",
    "                 num_filters=32,\n",
    "                 kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            # 4 is for the 4 nucleotides\n",
    "            nn.Conv1d(4, num_filters, kernel_size=kernel_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_filters*(seq_len-kernel_size+1), 1)\n",
    "        ) \n",
    "\n",
    "    def forward(self, xb):\n",
    "        # reshape view to batch_size x 4channel x seq_len\n",
    "        # permute to put channel in correct order\n",
    "        xb = xb.permute(0,2,1) \n",
    "        \n",
    "        #print(xb.shape)\n",
    "        out = self.conv_net(xb)\n",
    "        return out\n",
    "    \n",
    "    # __FOOTNOTE 1__\n",
    "\n",
    "model = Promoter_CNN(max_len)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'promoterDataset' object has no attribute 'vec_seqs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test_loop(test_dataloader, model, loss_fn)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Set the model to training mode - important for batch normalization and dropout layers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Unnecessary in this situation but added for best practices\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction and loss\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[32], line 18\u001b[0m, in \u001b[0;36mpromoterDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 18\u001b[0m     seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvec_seqs\u001b[49m[index]\n\u001b[1;32m     19\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel[index]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seq, label\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'promoterDataset' object has no attribute 'vec_seqs'"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EvoAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import getpass\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing SynBioHub to pull iGEM parts registry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.post(\n",
    "#     'https://synbiohub.org/login',\n",
    "#     headers={\n",
    "#         'Accept': 'text/plain'\n",
    "#     },\n",
    "#     data={\n",
    "#         'email': input('SynBioHub email: '),\n",
    "#         'password' : getpass.getpass('Password: '),\n",
    "#         },\n",
    "# )\n",
    "\n",
    "# print(response.status_code)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unable to access SynBioHub right\n",
    "\n",
    "Need to build method to access larger database of genetic parts sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(\n",
    "#     'https://synbiohub.org/rootCollections',\n",
    "#     headers={\n",
    "#         'Accept': 'text/plain',\n",
    "#         'X-authorization': response.content\n",
    "#         },\n",
    "# )\n",
    "\n",
    "# print(response.status_code)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(\n",
    "#     'https://synbiohub.org/public/igem/igem_collection/1/sbol',\n",
    "#     headers={\n",
    "#         'Accept': 'text/plain',\n",
    "#         'X-authorization': response.content\n",
    "#         },\n",
    "# )\n",
    "\n",
    "# print(response.status_code)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Search for DNA sequences using regular expression\n",
    "# dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', response.content.decode('utf-8'), re.DOTALL)\n",
    "\n",
    "# # Create a pandas dataframe\n",
    "# df = pd.DataFrame(dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "\n",
    "# # Print the dataframe\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using downloaded promoter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "23\n",
      "611\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "promoters_2019 = open('./data_collection/SBOL_Files/iGEM_2019_Promoters_collection.xml').read()\n",
    "\n",
    "rbs_2019 = open('./data_collection/SBOL_files/iGEM_2019_RBSs_collection.xml').read()\n",
    "\n",
    "cds_2019 = open('./data_collection/SBOL_files/iGEM_2019_CDS_collection.xml').read()\n",
    "\n",
    "t_2019 = open('data_collection/SBOL_files/iGEM_2019_Terminators_collection.xml').read()\n",
    "\n",
    "\n",
    "# Search for DNA sequences using regular expression\n",
    "# Promoters\n",
    "p19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', promoters_2019, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "p19_df = pd.DataFrame(p19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(p19_df))\n",
    "# Print the dataframe\n",
    "#print(p19_df)\n",
    "\n",
    "# RBS\n",
    "rbs19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', rbs_2019, re.DOTALL)\n",
    "rbs19_df = pd.DataFrame(rbs19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "#print(rbs19_df)\n",
    "print(len(rbs19_df))\n",
    "\n",
    "# CDS\n",
    "cds19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', cds_2019, re.DOTALL)\n",
    "cds19_df = pd.DataFrame(cds19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(cds19_df))\n",
    "\n",
    "# Terminators\n",
    "t19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', t_2019, re.DOTALL)\n",
    "t19_df = pd.DataFrame(t19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(t19_df))\n",
    "\n",
    "# why is the first name of the df the name of the collection? \n",
    "# for now, will remove first row so that we have realistic names\n",
    "p19_df = p19_df.drop(p19_df.index[0])\n",
    "\n",
    "# add in promoter label for these seqs\n",
    "p19_df['Element'] = \"Promoter\"\n",
    "\n",
    "rbs19_df = rbs19_df.drop(rbs19_df.index[0])\n",
    "rbs19_df['Element'] = \"RBS\"\n",
    "\n",
    "cds19_df = cds19_df.drop(cds19_df.index[0])\n",
    "cds19_df['Element'] = \"CDS\"\n",
    "\n",
    "t19_df = t19_df.drop(t19_df.index[0])\n",
    "t19_df['Element'] = \"Terminator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>DNA Sequence</th>\n",
       "      <th>Element</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BBa_J05209</td>\n",
       "      <td>taacaccgtgcgtgttgactattttacctctggcggtgataatggttgc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BBa_I732406</td>\n",
       "      <td>aattgtgagcgctcacaatttttacactttatgcttccggctcgta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BBa_K1773016</td>\n",
       "      <td>acctgtaggatcgtacaggtttacgcaagaaaatggtttgttatag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BBa_K2117000</td>\n",
       "      <td>agagaccgggttggcggcgtatttgtgtcccaaaaaacagccccaa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BBa_K1444002</td>\n",
       "      <td>ggagttctgagaattggtatgccttataagtccaattaacagttga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>3171</td>\n",
       "      <td>BBa_R2108</td>\n",
       "      <td>tttatcaaaaagagtgttgacatttttaagtcccacgcgtgggatt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>3172</td>\n",
       "      <td>BBa_K1444025</td>\n",
       "      <td>ggagttctgagaattggtatgccttataagtccaattaacagttga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>3173</td>\n",
       "      <td>BBa_K879037</td>\n",
       "      <td>ttgatattgtgagcggataacaagatatc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>3174</td>\n",
       "      <td>BBa_I15008</td>\n",
       "      <td>atgagtgtcaacttagcttcccagttgcgggaagggacgaaaaaat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>3175</td>\n",
       "      <td>BBa_K1387002</td>\n",
       "      <td>atgtccagattagataaaagtaaagtgattaacagcgcattagagc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index          Name                                       DNA Sequence  \\\n",
       "0         1    BBa_J05209  taacaccgtgcgtgttgactattttacctctggcggtgataatggttgc   \n",
       "1         2   BBa_I732406  aattgtgagcgctcacaatttttacactttatgcttccggctcgta...   \n",
       "2         3  BBa_K1773016  acctgtaggatcgtacaggtttacgcaagaaaatggtttgttatag...   \n",
       "3         4  BBa_K2117000  agagaccgggttggcggcgtatttgtgtcccaaaaaacagccccaa...   \n",
       "4         5  BBa_K1444002  ggagttctgagaattggtatgccttataagtccaattaacagttga...   \n",
       "...     ...           ...                                                ...   \n",
       "3170   3171     BBa_R2108  tttatcaaaaagagtgttgacatttttaagtcccacgcgtgggatt...   \n",
       "3171   3172  BBa_K1444025  ggagttctgagaattggtatgccttataagtccaattaacagttga...   \n",
       "3172   3173   BBa_K879037                      ttgatattgtgagcggataacaagatatc   \n",
       "3173   3174    BBa_I15008  atgagtgtcaacttagcttcccagttgcgggaagggacgaaaaaat...   \n",
       "3174   3175  BBa_K1387002  atgtccagattagataaaagtaaagtgattaacagcgcattagagc...   \n",
       "\n",
       "      Element  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "3170        1  \n",
       "3171        1  \n",
       "3172        1  \n",
       "3173        1  \n",
       "3174        1  \n",
       "\n",
       "[2805 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "promoters_toValidate = open('./data_collection/SBOL_files/iGEM_Promoters_collection.xml').read()\n",
    "\n",
    "allPromoters_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', promoters_toValidate, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "allPromoters_df = pd.DataFrame(allPromoters_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "allPromoters_df = allPromoters_df.drop(allPromoters_df.index[0]).reset_index()\n",
    "allPromoters_df['Element'] = 1\n",
    "\n",
    "#drop unreasonably length promoters\n",
    "for idx in allPromoters_df.index.to_list():\n",
    "    if len(allPromoters_df.loc[idx, 'DNA Sequence']) > 1000: \n",
    "        allPromoters_df = allPromoters_df.drop(index=idx)\n",
    "\n",
    "allPromoters_df.reset_index()\n",
    "allPromoters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DNA Sequence</th>\n",
       "      <th>Element</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBa_K823010</td>\n",
       "      <td>ctgatggctagctcagtcctagggattatgctagc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBa_R0010</td>\n",
       "      <td>caatacgcaaaccgcctctccccgcgcgttggccgattcattaatg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBa_K823005</td>\n",
       "      <td>tttacagctagctcagtcctaggtattatgctagc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBa_K823012</td>\n",
       "      <td>tttatagctagctcagtcctaggtacaatgctagc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBa_K733013</td>\n",
       "      <td>aattttgtcaaaataattttattgacaacgtcttattaacgttgat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>BBa_K861090</td>\n",
       "      <td>atgataaggcaggttatccagcgaataagcaaccctgaagcaagca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>BBa_K1150013</td>\n",
       "      <td>gcaggctcc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>BBa_B0013</td>\n",
       "      <td>aaaaaatcaaactggctcaccttcgggtgggcctttttgcgtttata</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>BBa_B0023</td>\n",
       "      <td>tataaacgcaaaaaggcccacccgaaggtgagccagtttgatttttt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>BBa_B0012</td>\n",
       "      <td>tcacactggctcaccttcgggtgggcctttctgcgtttata</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name                                       DNA Sequence Element\n",
       "0     BBa_K823010                ctgatggctagctcagtcctagggattatgctagc       1\n",
       "1       BBa_R0010  caatacgcaaaccgcctctccccgcgcgttggccgattcattaatg...       1\n",
       "2     BBa_K823005                tttacagctagctcagtcctaggtattatgctagc       1\n",
       "3     BBa_K823012                tttatagctagctcagtcctaggtacaatgctagc       1\n",
       "4     BBa_K733013  aattttgtcaaaataattttattgacaacgtcttattaacgttgat...       1\n",
       "..            ...                                                ...     ...\n",
       "774   BBa_K861090  atgataaggcaggttatccagcgaataagcaaccctgaagcaagca...       0\n",
       "775  BBa_K1150013                                          gcaggctcc       0\n",
       "780     BBa_B0013    aaaaaatcaaactggctcaccttcgggtgggcctttttgcgtttata       0\n",
       "781     BBa_B0023    tataaacgcaaaaaggcccacccgaaggtgagccagtttgatttttt       0\n",
       "782     BBa_B0012          tcacactggctcaccttcgggtgggcctttctgcgtttata       0\n",
       "\n",
       "[544 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "pro_rbs_cds_ter_df = pd.concat([p19_df, rbs19_df, cds19_df, t19_df], ignore_index=True)\n",
    "for i in range(len(pro_rbs_cds_ter_df)):\n",
    "    if pro_rbs_cds_ter_df.loc[i]['Element'] == 'Promoter':\n",
    "        pro_rbs_cds_ter_df.at[i,'Element'] = 1\n",
    "    else: \n",
    "        pro_rbs_cds_ter_df.at[i,'Element'] = 0\n",
    "\n",
    "for idx in pro_rbs_cds_ter_df.index.to_list():\n",
    "    if len(pro_rbs_cds_ter_df.loc[idx, 'DNA Sequence']) > 1000:\n",
    "        pro_rbs_cds_ter_df = pro_rbs_cds_ter_df.drop(index=idx)\n",
    "pro_rbs_cds_ter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the string data into vectors for use in PyTorch\n",
    "We translate sequnce data into a matrix form to be analyzed\n",
    "\n",
    "'a': [1.0, 0.0, 0.0, 0.0]  \n",
    "'c': [0.0, 1.0, 0.0, 0.0]  \n",
    "'g': [0.0, 0.0, 1.0, 0.0]  \n",
    "'t': [0.0, 0.0, 0.0, 1.0]  \n",
    "\n",
    "We also generate a correponding list of element labels to use for training with promoters as 1 and other parts as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequence(seq, max_len):\n",
    "    vec_dict = {'a': [1.0, 0.0, 0.0, 0.0],\n",
    "                'c': [0.0, 1.0, 0.0, 0.0],\n",
    "                'g': [0.0, 0.0, 1.0, 0.0],\n",
    "                't': [0.0, 0.0, 0.0, 1.0]}\n",
    "    vector = np.array([vec_dict[n] for n in seq])\n",
    "\n",
    "    vector = np.append(vector, np.zeros(((max_len-len(vector)), 4)))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros((2,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PyTorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# currently cells 33 and 34 filter the datadrames to sequences < 1000 in length\n",
    "\n",
    "max_len = allPromoters_df['DNA Sequence'].map(len).max()\n",
    "print(max_len)\n",
    "new_vec = torch.tensor(vectorize_sequence(allPromoters_df.loc[1]['DNA Sequence'], max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the dataset class\n",
    "class promoterDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 seq_col='DNA Sequence', \n",
    "                 element_col='Element'):\n",
    "\n",
    "        self.seqs = df[seq_col].to_list()\n",
    "        self.seq_len = len(self.seqs[0])\n",
    "        \n",
    "        ### X values  ****we introduce padding to these tensors in order to create the stack. This may introduce bias.\n",
    "        max_len = df[seq_col].map(len).max()\n",
    "        self.veq_seqs = torch.stack([torch.tensor(vectorize_sequence(x, max_len), dtype=torch.float32) for x in self.seqs])\n",
    "\n",
    "        ### Y values\n",
    "        self.labels = torch.tensor(list(df[element_col].values)).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        seq = self.veq_seqs[index]\n",
    "        label = self.labels[index]\n",
    "        return seq, label\n",
    "    \n",
    "#initialize the data into correct form\n",
    "training_data = promoterDataset(allPromoters_df)\n",
    "test_data = promoterDataset(pro_rbs_cds_ter_df)\n",
    "\n",
    "train_dataloader = DataLoader(training_data)\n",
    "test_dataloader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the model\n",
    "\n",
    "Optimizes GPU > MPS > CPU based on PyTorch tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where I am stuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic CNN model based on https://github.com/erinhwilson/dna-pytorch-tutorial/blob/c3abe167889a0018dba587ae7c3685920dbb928b/basic_DNA_tutorial.ipynb\n",
    "\n",
    "class Promoter_CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_len,\n",
    "                 num_filters=32,\n",
    "                 kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            # 4 is for the 4 nucleotides\n",
    "            nn.Conv1d(4, num_filters, kernel_size=kernel_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_filters*(seq_len-kernel_size+1), 1)\n",
    "        ) \n",
    "\n",
    "    def forward(self, xb):\n",
    "        # reshape view to batch_size x 4channel x seq_len\n",
    "        # permute to put channel in correct order\n",
    "        xb = xb.permute(1,0) \n",
    "        \n",
    "        #print(xb.shape)\n",
    "        out = self.conv_net(xb)\n",
    "        return out\n",
    "    \n",
    "    # __FOOTNOTE 1__\n",
    "\n",
    "model = Promoter_CNN(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 4, 3], expected input[1, 4000, 1] to have 4 channels, but got 4000 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test_loop(test_dataloader, model, loss_fn)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[60], line 8\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[58], line 25\u001b[0m, in \u001b[0;36mPromoter_CNN.forward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     22\u001b[0m xb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#print(xb.shape)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/EvoAI/lib/python3.12/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 4, 3], expected input[1, 4000, 1] to have 4 channels, but got 4000 channels instead"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EvoAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
